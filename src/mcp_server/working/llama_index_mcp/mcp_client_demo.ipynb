{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex MCP Client Demo\n",
    "\n",
    "This notebook demonstrates how to use the **LlamaIndex MCP implementation** (`BasicMCPClient` + `McpToolSpec`) to interact with the running NSO MCP server.\n",
    "\n",
    "## Prerequisites\n",
    "- LlamaIndex NSO MCP Server is running\n",
    "- Virtual environment is activated\n",
    "- All required packages are installed\n",
    "\n",
    "## ‚ö†Ô∏è Important Note About Validation Errors\n",
    "\n",
    "**Known Issue**: The LlamaIndex MCP client shows validation errors when calling tools. This is a **fundamental compatibility issue** between the MCP server's `CallToolResult` format and what the LlamaIndex MCP client expects.\n",
    "\n",
    "**‚úÖ What Works**:\n",
    "- Connection to MCP server\n",
    "- Tool discovery and listing\n",
    "- Server-side tool execution (NSO functions work correctly)\n",
    "\n",
    "**‚ùå What Doesn't Work**:\n",
    "- Client-side validation of tool responses\n",
    "- Clean error-free tool calling\n",
    "- Production use with MCP\n",
    "\n",
    "**üîß Recommended Solution**: For production use, use the **pure LlamaIndex approach** without MCP (see `pure_llama_nso_agent.py`) which works perfectly without validation issues.\n",
    "\n",
    "**üìù This Demo**: Shows the MCP approach for educational purposes, but expect validation errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ mcp is already installed\n",
      "üì¶ Installing llama-index-tools-mcp...\n",
      "Requirement already satisfied: llama-index-tools-mcp in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (0.4.2)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-tools-mcp) (0.14.5)\n",
      "Requirement already satisfied: mcp<2,>=1.9.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-tools-mcp) (1.16.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-tools-mcp) (2.12.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.13.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2025.9.0)\n",
      "Requirement already satisfied: httpx in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<3,>=2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.8.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.9.2)\n",
      "Requirement already satisfied: numpy in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.3.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (12.0.0)\n",
      "Requirement already satisfied: platformdirs in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (4.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.17.3)\n",
      "Requirement already satisfied: anyio>=4.5 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.37.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic<3,>=2.0.0->llama-index-tools-mcp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic<3,>=2.0.0->llama-index-tools-mcp) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic<3,>=2.0.0->llama-index-tools-mcp) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from anyio>=4.5->mcp<2,>=1.9.1->llama-index-tools-mcp) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from anyio>=4.5->mcp<2,>=1.9.1->llama-index-tools-mcp) (1.3.1)\n",
      "Requirement already satisfied: griffe in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.1.6)\n",
      "Requirement already satisfied: certifi in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.1->llama-index-tools-mcp) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.1->llama-index-tools-mcp) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.1->llama-index-tools-mcp) (0.27.1)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.4.2)\n",
      "Requirement already satisfied: click in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2025.9.18)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.9.1->llama-index-tools-mcp) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-tools-mcp) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing llama-index-core...\n",
      "Requirement already satisfied: llama-index-core in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (0.14.5)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (3.13.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (2025.9.0)\n",
      "Requirement already satisfied: httpx in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<3,>=2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (2.8.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (3.9.2)\n",
      "Requirement already satisfied: numpy in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (2.3.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (12.0.0)\n",
      "Requirement already satisfied: platformdirs in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (2.12.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.22.0)\n",
      "Requirement already satisfied: griffe in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-workflows<3,>=2->llama-index-core) (0.4.2)\n",
      "Requirement already satisfied: click in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core) (2025.9.18)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (2025.10.5)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core) (3.26.1)\n",
      "Requirement already satisfied: anyio in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-core) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-core) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (25.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from anyio->httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing llama-index-llms-azure-openai...\n",
      "Requirement already satisfied: llama-index-llms-azure-openai in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (0.4.2)\n",
      "Requirement already satisfied: azure-identity<2,>=1.15.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-llms-azure-openai) (1.25.1)\n",
      "Requirement already satisfied: httpx in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-llms-azure-openai) (0.28.1)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.14.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-llms-azure-openai) (0.14.5)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-llms-azure-openai) (0.6.5)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (1.36.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (46.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (4.15.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.13.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2025.9.0)\n",
      "Requirement already satisfied: llama-index-workflows<3,>=2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.8.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.9.2)\n",
      "Requirement already satisfied: numpy in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.3.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (12.0.0)\n",
      "Requirement already satisfied: platformdirs in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.12.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.17.3)\n",
      "Requirement already satisfied: openai<2,>=1.108.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-azure-openai) (1.109.1)\n",
      "Requirement already satisfied: anyio in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-llms-azure-openai) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-llms-azure-openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-llms-azure-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpx->llama-index-llms-azure-openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.22.0)\n",
      "Requirement already satisfied: griffe in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.1.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from cryptography>=2.5->azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (2.0.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.4.2)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (2.10.1)\n",
      "Requirement already satisfied: click in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2025.9.18)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-azure-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-azure-openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-azure-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.26.1)\n",
      "Requirement already satisfied: pycparser in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (2.23)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.3->llama-index-llms-azure-openai) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing python-dotenv...\n",
      "Requirement already satisfied: python-dotenv in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (1.1.1)\n",
      "üì¶ Installing nest-asyncio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest-asyncio in /Users/gudeng/MCP_Server/mcp_venv/lib/python3.13/site-packages (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    \"mcp\",\n",
    "    \"llama-index-tools-mcp\",\n",
    "    \"llama-index-core\",\n",
    "    \"llama-index-llms-azure-openai\",\n",
    "    \"python-dotenv\",\n",
    "    \"nest-asyncio\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# LlamaIndex MCP imports\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Environment setup\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Enable nested asyncio for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NSO environment configured: /Users/gudeng/NCS-614\n",
      "‚úÖ Python path updated with NSO API\n"
     ]
    }
   ],
   "source": [
    "# NSO Configuration\n",
    "NSO_DIR = \"/Users/gudeng/NCS-614\"\n",
    "os.environ['NCS_DIR'] = NSO_DIR\n",
    "os.environ['DYLD_LIBRARY_PATH'] = f'{NSO_DIR}/lib'\n",
    "os.environ['PYTHONPATH'] = f'{NSO_DIR}/src/ncs/pyapi'\n",
    "\n",
    "# Add NSO Python API to Python path\n",
    "nso_pyapi_path = f'{NSO_DIR}/src/ncs/pyapi'\n",
    "if nso_pyapi_path not in sys.path:\n",
    "    sys.path.insert(0, nso_pyapi_path)\n",
    "\n",
    "print(f\"‚úÖ NSO environment configured: {NSO_DIR}\")\n",
    "print(f\"‚úÖ Python path updated with NSO API\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create MCP Client and Test Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating LlamaIndex MCP Client...\n",
      "‚úÖ Connected to MCP server!\n",
      "‚úÖ Found 4 tools\n"
     ]
    }
   ],
   "source": [
    "# Create LlamaIndex MCP Client\n",
    "async def create_mcp_client():\n",
    "    \"\"\"Create and connect to MCP server using LlamaIndex BasicMCPClient.\"\"\"\n",
    "    try:\n",
    "        print(\"üîß Creating LlamaIndex MCP Client...\")\n",
    "        \n",
    "        # Create BasicMCPClient for local process\n",
    "        mcp_client = BasicMCPClient(\n",
    "            \"/Users/gudeng/MCP_Server/src/mcp_server/working/llama_index_mcp/start_fastmcp_nso_server.sh\",\n",
    "            args=[]\n",
    "        )\n",
    "        \n",
    "        # Create McpToolSpec\n",
    "        mcp_tool_spec = McpToolSpec(client=mcp_client)\n",
    "        \n",
    "        # Get tools from the server\n",
    "        tools = await mcp_tool_spec.to_tool_list_async()\n",
    "        \n",
    "        print(f\"‚úÖ Connected to MCP server!\")\n",
    "        print(f\"‚úÖ Found {len(tools)} tools\")\n",
    "        \n",
    "        return mcp_client, mcp_tool_spec, tools\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create MCP client: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, []\n",
    "\n",
    "# Create the MCP client\n",
    "mcp_client, mcp_tool_spec, tools = await create_mcp_client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. List Available Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available Tools:\n",
      "  ‚Ä¢ show_all_devices: Find out all available routers in the lab, return their names.\n",
      "    Schema: <class 'llama_index.tools.mcp.base.show_all_devices_Schema'>\n",
      "\n",
      "  ‚Ä¢ get_router_interfaces_config: Return configured interfaces (Loopback/GigabitEthernet/Ethernet) with IPv4 for a router.\n",
      "    Schema: <class 'llama_index.tools.mcp.base.get_router_interfaces_config_Schema'>\n",
      "\n",
      "  ‚Ä¢ configure_router_interface: Configure a router interface with IP address, description, and shutdown status.\n",
      "    Schema: <class 'llama_index.tools.mcp.base.configure_router_interface_Schema'>\n",
      "\n",
      "  ‚Ä¢ echo_text: Echo back the provided text (debug/health).\n",
      "    Schema: <class 'llama_index.tools.mcp.base.echo_text_Schema'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all available tools\n",
    "if tools:\n",
    "    print(\"üìã Available Tools:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  ‚Ä¢ {tool.metadata.name}: {tool.metadata.description}\")\n",
    "        print(f\"    Schema: {tool.metadata.fn_schema}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ùå No tools available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Individual Tools (With Expected Validation Errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing echo_text tool...\n",
      "‚ö†Ô∏è  Note: You may see validation errors below - this is expected!\n",
      "Result: meta=None content=[TextContent(type='text', text='Echo: Hello from Jupyter Notebook!', annotations=None, meta=None)] structuredContent={'result': 'Echo: Hello from Jupyter Notebook!'} isError=False\n"
     ]
    }
   ],
   "source": [
    "# Test echo_text tool\n",
    "async def test_echo_tool():\n",
    "    \"\"\"Test the echo_text tool.\"\"\"\n",
    "    if not tools:\n",
    "        print(\"‚ùå No tools available\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Find echo_text tool\n",
    "        echo_tool = None\n",
    "        for tool in tools:\n",
    "            if tool.metadata.name == \"echo_text\":\n",
    "                echo_tool = tool\n",
    "                break\n",
    "        \n",
    "        if not echo_tool:\n",
    "            print(\"‚ùå echo_text tool not found\")\n",
    "            return None\n",
    "        \n",
    "        print(\"üîß Testing echo_text tool...\")\n",
    "        print(\"‚ö†Ô∏è  Note: You may see validation errors below - this is expected!\")\n",
    "        result = await echo_tool.acall(text=\"Hello from Jupyter Notebook!\")\n",
    "        print(f\"Result: {result}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing echo_text: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Test echo tool\n",
    "echo_result = await test_echo_tool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing show_all_devices tool...\n",
      "‚ö†Ô∏è  Note: You may see validation errors below - this is expected!\n",
      "Result: meta=None content=[TextContent(type='text', text='Available devices: xr9kv-1, xr9kv-2, xr9kv-3', annotations=None, meta=None)] structuredContent={'result': 'Available devices: xr9kv-1, xr9kv-2, xr9kv-3'} isError=False\n"
     ]
    }
   ],
   "source": [
    "# Test show_all_devices tool\n",
    "async def test_devices_tool():\n",
    "    \"\"\"Test the show_all_devices tool.\"\"\"\n",
    "    if not tools:\n",
    "        print(\"‚ùå No tools available\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Find show_all_devices tool\n",
    "        devices_tool = None\n",
    "        for tool in tools:\n",
    "            if tool.metadata.name == \"show_all_devices\":\n",
    "                devices_tool = tool\n",
    "                break\n",
    "        \n",
    "        if not devices_tool:\n",
    "            print(\"‚ùå show_all_devices tool not found\")\n",
    "            return None\n",
    "        \n",
    "        print(\"üîß Testing show_all_devices tool...\")\n",
    "        print(\"‚ö†Ô∏è  Note: You may see validation errors below - this is expected!\")\n",
    "        result = await devices_tool.acall()\n",
    "        print(f\"Result: {result}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing show_all_devices: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Test devices tool\n",
    "devices_result = await test_devices_tool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing get_router_interfaces_config tool...\n",
      "‚ö†Ô∏è  Note: You may see validation errors below - this is expected!\n",
      "Result: meta=None content=[TextContent(type='text', text='Interfaces for xr9kv-3:\\n  GigabitEthernet/0/0/0/0: No IP configured\\n  GigabitEthernet/0/0/0/1: No IP configured\\n  GigabitEthernet/0/0/0/2: No IP configured\\n  Loopback/100: No IP configured', annotations=None, meta=None)] structuredContent={'result': 'Interfaces for xr9kv-3:\\n  GigabitEthernet/0/0/0/0: No IP configured\\n  GigabitEthernet/0/0/0/1: No IP configured\\n  GigabitEthernet/0/0/0/2: No IP configured\\n  Loopback/100: No IP configured'} isError=False\n"
     ]
    }
   ],
   "source": [
    "# Test get_router_interfaces_config tool\n",
    "async def test_interfaces_tool():\n",
    "    \"\"\"Test the get_router_interfaces_config tool.\"\"\"\n",
    "    if not tools:\n",
    "        print(\"‚ùå No tools available\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Find get_router_interfaces_config tool\n",
    "        interfaces_tool = None\n",
    "        for tool in tools:\n",
    "            if tool.metadata.name == \"get_router_interfaces_config\":\n",
    "                interfaces_tool = tool\n",
    "                break\n",
    "        \n",
    "        if not interfaces_tool:\n",
    "            print(\"‚ùå get_router_interfaces_config tool not found\")\n",
    "            return None\n",
    "        \n",
    "        print(\"üîß Testing get_router_interfaces_config tool...\")\n",
    "        print(\"‚ö†Ô∏è  Note: You may see validation errors below - this is expected!\")\n",
    "        result = await interfaces_tool.acall(router_name=\"xr9kv-3\")\n",
    "        print(f\"Result: {result}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing get_router_interfaces_config: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Test interfaces tool\n",
    "interfaces_result = await test_interfaces_tool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Tools with LlamaIndex Agent (Recommended Approach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creating LlamaIndex FunctionAgent with MCP tools...\n",
      "‚úÖ FunctionAgent created successfully!\n",
      "‚úÖ LLM configured: gpt-35-turbo\n",
      "‚úÖ Azure Deployment: None\n",
      "‚úÖ Endpoint: https://chat-ai.cisco.com\n"
     ]
    }
   ],
   "source": [
    "# Create LlamaIndex Agent with MCP Tools\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# Get Azure OpenAI token (same as Flask app)\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "token_url = os.getenv(\"TOKEN_URL\")\n",
    "llm_endpoint = os.getenv(\"LLM_ENDPOINT\")\n",
    "appkey = os.getenv(\"APP_KEY\")\n",
    "\n",
    "# Create Basic auth header (like Flask app)\n",
    "auth_string = f\"{client_id}:{client_secret}\"\n",
    "auth_key = base64.b64encode(auth_string.encode()).decode()\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    \"Authorization\": f\"Basic {auth_key}\",\n",
    "}\n",
    "\n",
    "token_response = requests.post(token_url, headers=headers, data=\"grant_type=client_credentials\")\n",
    "token = token_response.json().get(\"access_token\")\n",
    "\n",
    "# Create user parameter for additional_kwargs\n",
    "user_param = json.dumps({\"appkey\": appkey})\n",
    "\n",
    "# Initialize Azure OpenAI LLM (Fixed configuration matching Flask app)\n",
    "llm = AzureOpenAI(\n",
    "    azure_endpoint=llm_endpoint,\n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    deployment_name=\"gpt-4o-mini\",\n",
    "    api_key=token,\n",
    "    max_tokens=3000,\n",
    "    temperature=0.1,\n",
    "    additional_kwargs={\"user\": user_param}\n",
    ")\n",
    "\n",
    "# Create agent with MCP tools\n",
    "if tools:\n",
    "    print(\"ü§ñ Creating LlamaIndex FunctionAgent with MCP tools...\")\n",
    "    agent = FunctionAgent(\n",
    "        tools=tools,\n",
    "        llm=llm,\n",
    "        system_prompt=\"\"\"You are a network automation assistant. When users ask about:\n",
    "- Device lists: Use show_all_devices tool\n",
    "- Interface configurations: Use get_router_interfaces_config tool with the specific router name\n",
    "- Interface configuration changes: Use configure_router_interface tool with router_name, interface_name, and optional parameters (ip_address, description, shutdown)\n",
    "- Router 3 means xr9kv-3\n",
    "- Router 1 means xr9kv-1  \n",
    "- Router 2 means xr9kv-2\n",
    "\n",
    "IMPORTANT: Interface names must use the format \"Type/Number\" (e.g., \"Loopback/100\", \"GigabitEthernet/0/0/0/0\").\n",
    "When users say \"Loopback 100\" or \"Loopback100\", convert it to \"Loopback/100\".\n",
    "When users say \"GigabitEthernet 0/0/0/0\", convert it to \"GigabitEthernet/0/0/0/0\".\n",
    "\n",
    "Always use the appropriate tool to get the requested information or make configuration changes.\"\"\"\n",
    "    )\n",
    "    print(\"‚úÖ FunctionAgent created successfully!\")\n",
    "    print(f\"‚úÖ LLM configured: {llm.model}\")\n",
    "    print(f\"‚úÖ Azure Deployment: {llm.azure_deployment}\")\n",
    "    print(f\"‚úÖ Endpoint: {llm.azure_endpoint}\")\n",
    "else:\n",
    "    print(\"‚ùå No tools available to create agent\")\n",
    "    agent = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing agent with question:'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://chat-ai.cisco.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://chat-ai.cisco.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent Response:\n",
      "Here are the interface configurations for router xr9kv-3:\n",
      "\n",
      "- **GigabitEthernet/0/0/0/0**: No IP configured\n",
      "- **GigabitEthernet/0/0/0/1**: No IP configured\n",
      "- **GigabitEthernet/0/0/0/2**: No IP configured\n",
      "- **Loopback/100**: No IP configured\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with your question: \"show me all devices\"\n",
    "if agent:\n",
    "    print(\"üîß Testing agent with question:'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Ask the agent to show all devices (note: await is needed for FunctionAgent)\n",
    "        response = await agent.run(\"'can you get_router_interfaces_config for router xr9kv-3 \")\n",
    "        print(f\"\\nü§ñ Agent Response:\")\n",
    "        print(response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with agent: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå No agent available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing agent with question:'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://chat-ai.cisco.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://chat-ai.cisco.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent Response:\n",
      "The interface Loopback/101 has been successfully configured on all routers with the following IPv4 addresses:\n",
      "\n",
      "- **xr9kv-1**: IP Address 2.1.1.1\n",
      "- **xr9kv-2**: IP Address 2.1.1.2\n",
      "- **xr9kv-3**: IP Address 2.1.1.3\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with your question: \"show me all devices\"\n",
    "if agent:\n",
    "    print(\"üîß Testing agent with question:'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Ask the agent to show all devices (note: await is needed for FunctionAgent)\n",
    "        response = await agent.run(\"'can you configure interface Loopback 101 on all routers with ipv4 address 2.1.1.x x is basically the routers number \")\n",
    "        print(f\"\\nü§ñ Agent Response:\")\n",
    "        print(response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with agent: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå No agent available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Testing - Ask Your Own Questions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
